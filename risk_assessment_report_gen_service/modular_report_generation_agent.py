"""
Modular Report Generation Agent - Comprehensive reporting and visualization
Generates detailed reports from detection analysis results and risk assessments
"""

import os
import sys
from typing import Dict, List, Any, Optional
from datetime import datetime
import logging
import json
from pathlib import Path
import re

# Add current directory to path for imports
sys.path.append(os.path.dirname(__file__))

from postgresql_db_manager import PostgreSQLCloudScanDBManager

logger = logging.getLogger(__name__)

class ModularReportGenerationAgent:
    """
    Configuration-driven report generation agent for scan analysis and risk assessments
    Multi-client aware - all operations are scoped to a specific client_id
    """
    
    def __init__(self, config_manager = None, client_id: str = None):
        """
        Initialize the Report Generation Agent
        
        Args:
            config_manager: Configuration manager instance (optional, kept for compatibility)
            client_id: Client ID for multi-tenant operations
        """
        self.client_id = client_id
        # Keep config_manager for potential future use but don't create new instance
        self.config_manager = config_manager
        # Use postgresql_db_manager directly without config_manager to avoid path issues
        self.db_manager = PostgreSQLCloudScanDBManager(client_id=client_id)
        # Get OpenAI API key from environment directly
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        # Placeholders for user info (to be set by frontend in future)
        self.company = None
        self.name = None
        self.email = None
        
        # Set up temporary reports directory for Docker compatibility
        import tempfile
        self.reports_dir = Path(tempfile.gettempdir()) / "risk_reports"
        self.reports_dir.mkdir(exist_ok=True)
        
        # Initialize AI reporting if LLM is available
        try:
            from llm_client import get_llm_client
            self.llm_client = get_llm_client()
            self.ai_reporting_available = self.llm_client.available
            logger.info(f"LLM client initialized: {self.llm_client.provider}")
        except Exception as e:
            self.llm_client = None
            self.ai_reporting_available = False
            logger.warning(f"LLM client initialization failed: {e}")
            logger.warning("Using standard reporting without AI enhancement")
        
        logger.info("‚úÖ Modular Report Generation Agent initialized")
    
    def fetch_latest_risk_assessment(self) -> Optional[Dict[str, Any]]:
        """
        Fetch the latest risk assessment for the client_id from the risk_assessments table
        
        Returns:
            Dictionary with risk assessment data or None if no data found
        """
        try:
            conn = self.db_manager.get_connection()
            cursor = conn.cursor()
            query = """
                SELECT assessment_id, total_data_sources, total_sdes, scanned_sdes, 
                       high_risk_sdes, total_sensitive_records, scans_completed, 
                       last_scan_time, next_scheduled_scan, risk_score, 
                       confidence_score, llm_summary
                FROM risk_assessments
                WHERE client_id = %s
                ORDER BY timestamp DESC
                LIMIT 1
            """
            cursor.execute(query, (self.client_id,))
            result = cursor.fetchone()
            conn.close()
            
            if not result:
                logger.warning(f"No risk assessment found for client_id: {self.client_id}")
                return None
            
            return {
                'assessment_id': result['assessment_id'],
                'total_data_sources': result['total_data_sources'],
                'total_sdes': result['total_sdes'],
                'scanned_sdes': result['scanned_sdes'],
                'high_risk_sdes': result['high_risk_sdes'],
                'total_sensitive_records': result['total_sensitive_records'],
                'scans_completed': result['scans_completed'],
                'last_scan_time': result['last_scan_time'],
                'next_scheduled_scan': result['next_scheduled_scan'],
                'risk_score': result['risk_score'],
                'confidence_score': result['confidence_score'],
                'llm_summary': result['llm_summary']
            }
        except Exception as e:
            logger.error(f"Error fetching risk assessment for client_id {self.client_id}: {e}")
            return None
    
    def generate_risk_assessment_report(self) -> Dict[str, Any]:
        """
        Generate a LaTeX-based risk assessment report for the latest client data
        
        Returns:
            Dictionary with report file paths and metadata
        """
        risk_data = self.fetch_latest_risk_assessment()
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if not risk_data:
            # Generate a fallback report indicating no data
            report_data = {
                'client_id': self.client_id,
                'status': 'no_data',
                'message': 'No risk analysis was performed yet for this client.',
                'report_metadata': {
                    'generated_at': datetime.now().isoformat(),
                    'report_version': '1.0',
                    'agent_version': 'modular_v1'
                }
            }
        else:
            report_data = {
                'client_id': self.client_id,
                'status': 'success',
                'risk_data': risk_data,
                'report_metadata': {
                    'generated_at': datetime.now().isoformat(),
                    'report_version': '1.0',
                    'agent_version': 'modular_v1'
                }
            }
        
        generated_reports = {
            'latex_report': self._generate_latex_report(report_data, timestamp),
            'html_preview': self._generate_html_preview(report_data, timestamp)
        }
        
        return {
            'client_id': self.client_id,
            'generated_reports': generated_reports,
            'status': report_data['status'],
            'generation_timestamp': datetime.now().isoformat()
        }
    
    def _get_user_info(self):
        """
        Returns company, name, email for report header.
        These should be set as instance variables (self.company, self.name, self.email) by the caller (e.g., via frontend input).
        """
        company = self.company or 'Unknown Company'
        name = self.name or 'Unknown User'
        email = self.email or 'user@example.com'
        return company, name, email

    def _sanitize_filename(self, name):
        return re.sub(r'[^A-Za-z0-9]+', '_', name).strip('_')
    
    def _format_llm_summary(self, summary_text: str) -> str:
        """
        Format LLM summary text with bullet points and better structure
        """
        if not summary_text or summary_text == 'No AI analysis available.':
            return 'No AI analysis available.'
        
        # Split the text into sections
        lines = summary_text.split('\n')
        formatted_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Check if line starts with common patterns that indicate a point
            if any(line.startswith(pattern) for pattern in ['‚Ä¢', '-', '*', '1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '10.']):
                # Already has a bullet point, just format it
                formatted_lines.append(f"‚Ä¢ {line.lstrip('‚Ä¢-*1234567890. ')}")
            elif line.lower().startswith(('risk summary:', 'actionable recommendations:', 'summary:', 'recommendations:')):
                # Section headers
                formatted_lines.append(f"<b>{line}</b>")
            elif any(keyword in line.lower() for keyword in ['risk', 'recommendation', 'action', 'suggestion', 'advice', 'measure', 'step']):
                # Likely a recommendation or important point
                formatted_lines.append(f"‚Ä¢ {line}")
            elif len(line) > 50:  # Long lines are likely paragraphs
                # Split long paragraphs into sentences and add bullets
                sentences = line.split('. ')
                for sentence in sentences:
                    if sentence.strip():
                        formatted_lines.append(f"‚Ä¢ {sentence.strip()}")
            else:
                # Regular text, keep as is
                formatted_lines.append(line)
        
        # Join with line breaks
        return '<br/>'.join(formatted_lines)

    def _generate_latex_report(self, report_data: Dict[str, Any], timestamp: str) -> str:
        """
        (DISABLED) Generate a one-page LaTeX report with constant colors
        """
        # LaTeX report generation is disabled in this version.
        return "LaTeX report generation is currently disabled."
    
    def _generate_html_preview(self, report_data: Dict[str, Any], timestamp: str) -> str:
        """
        Generate an HTML preview for the frontend
        
        Args:
            report_data: Dictionary containing risk assessment data or no-data message
            timestamp: Timestamp for file naming
            
        Returns:
            Path to the generated HTML file
        """
        company, name, email = self._get_user_info()
        filename = f"risk_assessment_preview_{self.client_id}_{timestamp}.html"
        filepath = self.reports_dir / filename
        
        # Get current date for the report
        current_date = datetime.now().strftime('%Y-%m-%d')
        
        try:
            if report_data['status'] == 'no_data':
                html_content = fr"""
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Risk Analysis Report Preview - Client {self.client_id}</title>
    <style>
        body {{ font-family: 'Inter', Arial, sans-serif; margin: 0; background-color: #F7FAFC; }}
        .preview-outer {{ display: flex; justify-content: center; align-items: flex-start; min-height: 100vh; }}
        .container {{ max-width: 600px; width: 100%; margin: 32px 0; background: #FFFFFF; padding: 20px 16px; border-radius: 10px; box-shadow: 0 4px 12px rgba(0,0,0,0.08); }}
        .header {{ text-align: center; padding-bottom: 1rem; border-bottom: 2px solid #2B6CB0; }}
        .header h1 {{ font-size: 1.5rem; color: #2B6CB0; }}
        .info {{ font-size: 0.875rem; color: #4A5568; }}
        .message {{ background: #EDF2F7; padding: 1rem; border-left: 5px solid #2B6CB0; border-radius: 8px; margin: 1rem 0; font-size: 0.95rem; color: #4A5568; }}
        .footer {{ text-align: center; color: #4A5568; margin-top: 1rem; font-size: 0.875rem; }}
    </style>
</head>
<body>
    <div class="preview-outer">
      <div class="container">
        <div class="header">
            <h1>Risk Analysis Report</h1>
            <div class="info">Company: {company} | Name: {name} | Email: {email} | Generated: {current_date}</div>
        </div>
        <div class="message">{report_data['message']}</div>
        <div class="footer">Powered by AI PLANETECH Solutions</div>
      </div>
    </div>
</body>
</html>
"""
            else:
                risk_data = report_data['risk_data']
                html_content = fr"""
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Risk Analysis Report Preview - Client {self.client_id}</title>
    <style>
        body {{ font-family: 'Inter', Arial, sans-serif; margin: 0; background-color: #F7FAFC; }}
        .preview-outer {{ display: flex; justify-content: center; align-items: flex-start; min-height: 100vh; }}
        .container {{ max-width: 600px; width: 100%; margin: 32px 0; background: #FFFFFF; padding: 20px 16px; border-radius: 10px; box-shadow: 0 4px 12px rgba(0,0,0,0.08); }}
        .header {{ text-align: center; padding-bottom: 1rem; border-bottom: 2px solid #2B6CB0; }}
        .header h1 {{ font-size: 1.5rem; color: #2B6CB0; }}
        .info {{ font-size: 0.875rem; color: #4A5568; display: flex; justify-content: center; gap: 1rem; flex-wrap: wrap; }}
        .context {{ background: #EDF2F7; padding: 1rem; border-left: 5px solid #2B6CB0; border-radius: 8px; margin: 1rem 0; font-size: 0.95rem; color: #4A5568; }}
        .section-title {{ font-size: 1.25rem; color: #1A202C; margin: 1rem 0 0.5rem; position: relative; }}
        .section-title::after {{ content: ''; position: absolute; bottom: -4px; left: 0; width: 50px; height: 2px; background: #2B6CB0; }}
        .summary-table {{ width: 100%; border-collapse: collapse; margin-bottom: 1rem; font-size: 0.95rem; }}
        .summary-table th, .summary-table td {{ border: 1px solid #E2E8F0; padding: 0.5rem; text-align: left; }}
        .summary-table th {{ background: #2B6CB0; color: #FFFFFF; font-weight: 600; font-size: 0.875rem; text-transform: uppercase; }}
        .summary-table td {{ background: #F9FAFB; color: #1A202C; }}
        .llm-summary {{ background: #F0FFF4; padding: 1rem; border-radius: 8px; border-left: 4px solid #27AE60; font-size: 0.95rem; color: #1A202C; margin-bottom: 1rem; }}
        .footer {{ text-align: center; color: #4A5568; margin-top: 1rem; font-size: 0.875rem; }}
    </style>
</head>
<body>
    <div class="preview-outer">
      <div class="container">
        <div class="header">
            <h1>Risk Analysis Report</h1>
            <div class="info">
                <span>Company: {company}</span>
                <span>Name: {name}</span>
                <span>Email: {email}</span>
                <span>Generated: {current_date}</span>
            </div>
        </div>
        <div class="context">
            This is a risk analysis report generated on <strong>{current_date}</strong>. It outlines the current state of data risk posture based on scanning and sensitivity metrics from your systems.
        </div>
        <h2 class="section-title">Summary Metrics</h2>
        <table class="summary-table">
            <thead>
                <tr><th>Metric</th><th>Value</th></tr>
            </thead>
            <tbody>
                <tr><td>Total Data Sources</td><td>{risk_data['total_data_sources']}</td></tr>
                <tr><td>Total SDEs</td><td>{risk_data['total_sdes']}</td></tr>
                <tr><td>Scanned SDEs</td><td>{risk_data['scanned_sdes']}</td></tr>
                <tr><td>High-Risk SDEs</td><td>{risk_data['high_risk_sdes']}</td></tr>
                <tr><td>Total Sensitive Records</td><td>{risk_data['total_sensitive_records']}</td></tr>
                <tr><td>Scans Completed</td><td>{risk_data['scans_completed']}</td></tr>
                <tr><td>Last Scan Time</td><td>{risk_data['last_scan_time']}</td></tr>
                <tr><td>Next Scheduled Scan</td><td>{risk_data['next_scheduled_scan']}</td></tr>
                <tr><td>Risk Score</td><td>{risk_data['risk_score']}</td></tr>
                <tr><td>Confidence Score</td><td>{risk_data['confidence_score']}%</td></tr>
            </tbody>
        </table>
        <h2 class="section-title">LLM Summary</h2>
        <div class="llm-summary">{risk_data['llm_summary'] or 'No summary available.'}</div>
        <div class="footer">Powered by AI PLANETECH Solutions</div>
      </div>
    </div>
</body>
</html>
"""
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            logger.info(f"HTML preview generated: {filepath}")
            return str(filepath)
        except Exception as e:
            logger.error(f"Failed to generate HTML preview: {e}")
            return f"Error: {e}"
    
    def generate_pdf_report(self) -> str:
        """
        Generate a PDF using reportlab only - no permanent storage
        Returns:
            Path to the generated PDF file
        """
        report_result = self.generate_risk_assessment_report()
        company, _, _ = self._get_user_info()
        safe_company = self._sanitize_filename(company)
        pdf_filename = f"risk_report_{safe_company}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
        pdf_filepath = self.reports_dir / pdf_filename
        
        # Use reportlab only
        logger.info("Generating PDF using reportlab...")
        pdf_path = self._generate_simple_pdf_fallback(report_result, datetime.now().strftime('%Y%m%d_%H%M%S'))
        
        # Don't cleanup immediately - let the file be served first
        # Cleanup will happen through background processes
        
        return pdf_path
    
    def _cleanup_all_reports(self):
        """
        Clean up old report files but preserve recent HTML files for frontend preview
        """
        try:
            current_time = datetime.now()
            # Keep HTML files for 5 minutes to allow frontend preview
            html_retention_minutes = 5
            
            for file_path in self.reports_dir.glob("*"):
                try:
                    # Check if file is older than retention period
                    file_age = current_time - datetime.fromtimestamp(file_path.stat().st_mtime)
                    
                    # Delete PDF files immediately, keep HTML files for preview
                    if file_path.suffix.lower() == '.pdf':
                        file_path.unlink()
                        logger.info(f"Deleted PDF file: {file_path.name}")
                    elif file_path.suffix.lower() == '.html':
                        # Keep HTML files for frontend preview
                        if file_age.total_seconds() > (html_retention_minutes * 60):
                            file_path.unlink()
                            logger.info(f"Deleted old HTML file: {file_path.name}")
                        else:
                            logger.info(f"Keeping HTML file for preview: {file_path.name}")
                    else:
                        # Delete other files immediately
                        file_path.unlink()
                        logger.info(f"Deleted other file: {file_path.name}")
                        
                except Exception as e:
                    logger.warning(f"Failed to delete file {file_path.name}: {e}")
                        
        except Exception as e:
            logger.warning(f"Failed to cleanup reports: {e}")
    
    def cleanup_report_file(self, file_path: str):
        """
        Delete a specific report file, but preserve HTML files for frontend preview
        """
        try:
            file_path_obj = Path(file_path)
            if file_path_obj.exists():
                # Don't immediately delete HTML files - let them be cleaned up by the retention logic
                if file_path_obj.suffix.lower() == '.html':
                    logger.info(f"Keeping HTML file for frontend preview: {file_path}")
                else:
                    file_path_obj.unlink()
                    logger.info(f"Cleaned up report file: {file_path}")
        except Exception as e:
            logger.warning(f"Failed to cleanup file {file_path}: {e}")
    
    def cleanup_old_html_files(self, max_age_minutes: int = 5):
        """
        Manually clean up HTML files older than specified age
        """
        try:
            current_time = datetime.now()
            cleaned_count = 0
            
            for file_path in self.reports_dir.glob("*.html"):
                try:
                    file_age = current_time - datetime.fromtimestamp(file_path.stat().st_mtime)
                    if file_age.total_seconds() > (max_age_minutes * 60):
                        file_path.unlink()
                        logger.info(f"Cleaned up old HTML file: {file_path.name}")
                        cleaned_count += 1
                except Exception as e:
                    logger.warning(f"Failed to delete old HTML file {file_path.name}: {e}")
            
            logger.info(f"Cleaned up {cleaned_count} old HTML files")
        except Exception as e:
            logger.warning(f"Failed to cleanup old HTML files: {e}")
    
    def cleanup_all_session_files(self):
        """
        Clean up all files from current session but preserve recent HTML files for frontend preview
        """
        try:
            current_time = datetime.now()
            # Keep HTML files for 5 minutes to allow frontend preview
            html_retention_minutes = 5
            
            for file_path in self.reports_dir.glob("*"):
                try:
                    # Check if file is older than retention period
                    file_age = current_time - datetime.fromtimestamp(file_path.stat().st_mtime)
                    
                    # Delete PDF files immediately, keep HTML files for preview
                    if file_path.suffix.lower() == '.pdf':
                        file_path.unlink()
                        logger.info(f"Cleaned up PDF session file: {file_path.name}")
                    elif file_path.suffix.lower() == '.html':
                        # Keep HTML files for frontend preview
                        if file_age.total_seconds() > (html_retention_minutes * 60):
                            file_path.unlink()
                            logger.info(f"Cleaned up old HTML session file: {file_path.name}")
                        else:
                            logger.info(f"Keeping HTML session file for preview: {file_path.name}")
                    else:
                        # Delete other files immediately
                        file_path.unlink()
                        logger.info(f"Cleaned up other session file: {file_path.name}")
                except Exception as e:
                    logger.warning(f"Failed to delete session file {file_path.name}: {e}")
        except Exception as e:
            logger.warning(f"Failed to cleanup session files: {e}")
    
    def _generate_simple_pdf_fallback(self, report_data: Dict[str, Any], timestamp: str) -> str:
        """
        Generate a visually appealing PDF using reportlab with professional styling
        """
        try:
            from reportlab.lib.pagesizes import letter
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
            from reportlab.lib.units import inch
            from reportlab.lib import colors
            from reportlab.pdfgen import canvas
            from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_RIGHT
            
            company, name, email = self._get_user_info()
            safe_company = self._sanitize_filename(company)
            pdf_filename = f"risk_report_{safe_company}_{timestamp}.pdf"
            pdf_filepath = self.reports_dir / pdf_filename
            
            # Fetch latest risk assessment data directly from database
            risk_data = self.fetch_latest_risk_assessment()
            
            # Create the PDF document with margins
            doc = SimpleDocTemplate(str(pdf_filepath), pagesize=letter, 
                                  leftMargin=0.75*inch, rightMargin=0.75*inch,
                                  topMargin=0.75*inch, bottomMargin=0.75*inch)
            styles = getSampleStyleSheet()
            story = []
            
            # Custom color scheme - All text in black
            primary_color = colors.black  # Black instead of Blue
            secondary_color = colors.black  # Black instead of Gray
            accent_color = colors.black  # Black instead of Red
            success_color = colors.black  # Black instead of Green
            warning_color = colors.black  # Black instead of Yellow
            light_bg = colors.HexColor('#F7FAFC')  # Light background
            dark_bg = colors.black  # Black text
            
            # Enhanced title style
            title_style = ParagraphStyle(
                'EnhancedTitle',
                parent=styles['Heading1'],
                fontSize=24,
                fontName='Helvetica-Bold',
                textColor=primary_color,
                spaceAfter=20,
                alignment=TA_CENTER,
                spaceBefore=10
            )
            
            # Subtitle style
            subtitle_style = ParagraphStyle(
                'Subtitle',
                parent=styles['Normal'],
                fontSize=12,
                fontName='Helvetica',
                textColor=secondary_color,
                alignment=TA_CENTER,
                spaceAfter=30
            )
            
            # Header info style
            header_style = ParagraphStyle(
                'HeaderInfo',
                parent=styles['Normal'],
                fontSize=10,
                fontName='Helvetica',
                textColor=secondary_color,
                spaceAfter=8,
                leftIndent=20
            )
            
            # Section header style
            section_style = ParagraphStyle(
                'SectionHeader',
                parent=styles['Heading2'],
                fontSize=14,
                fontName='Helvetica-Bold',
                textColor=primary_color,
                spaceAfter=15,
                spaceBefore=20,
                borderWidth=1,
                borderColor=primary_color,
                borderPadding=8,
                backColor=light_bg
            )
            
            # Normal text style
            normal_style = ParagraphStyle(
                'NormalText',
                parent=styles['Normal'],
                fontSize=10,
                fontName='Helvetica',
                textColor=dark_bg,
                spaceAfter=8,
                alignment=TA_LEFT
            )
            
            # Executive summary style
            summary_style = ParagraphStyle(
                'SummaryText',
                parent=styles['Normal'],
                fontSize=11,
                fontName='Helvetica',
                textColor=dark_bg,
                spaceAfter=12,
                alignment=TA_LEFT,
                leftIndent=15,
                backColor=colors.HexColor('#EDF2F7'),
                borderWidth=1,
                borderColor=colors.HexColor('#E2E8F0'),
                borderPadding=10
            )
            
            # Add title and subtitle
            story.append(Paragraph("üîí RISK ANALYSIS REPORT", title_style))
            story.append(Paragraph("Comprehensive Data Security Assessment", subtitle_style))
            
            # Add header information in a styled box
            story.append(Paragraph("üìã REPORT INFORMATION", section_style))
            story.append(Paragraph(f"<b>Company:</b> {company}", header_style))
            story.append(Paragraph(f"<b>Name:</b> {name}", header_style))
            story.append(Paragraph(f"<b>Email:</b> {email}", header_style))
            story.append(Paragraph(f"<b>Generated:</b> {datetime.now().strftime('%Y-%m-%d %H:%M')}", header_style))
            story.append(Paragraph(f"<b>Client ID:</b> {self.client_id}", header_style))
            
            if not risk_data:
                story.append(Paragraph("‚ö†Ô∏è NO DATA AVAILABLE", section_style))
                story.append(Paragraph("No risk assessment data found for this client. Please run a risk assessment first.", normal_style))
            else:
                # Risk Score Overview
                risk_score = risk_data.get('risk_score', 0)
                confidence_score = risk_data.get('confidence_score', 0)
                
                # Determine risk level and color
                if risk_score >= 70:
                    risk_level = "HIGH RISK"
                    risk_color = accent_color
                elif risk_score >= 40:
                    risk_level = "MEDIUM RISK"
                    risk_color = warning_color
                else:
                    risk_level = "LOW RISK"
                    risk_color = success_color
                
                story.append(Paragraph("üìä RISK OVERVIEW", section_style))
                
                # Risk score display - All text in black
                risk_score_text = f"""
                <table width="100%" cellpadding="10">
                <tr>
                    <td bgcolor="{light_bg}" width="50%">
                        <font color="black" size="10"><b>Risk Score: {risk_score}%</b></font><br/>
                        <font color="black" size="10">{risk_level}</font>
                    </td>
                    <td bgcolor="{light_bg}" width="50%">
                        <font color="black" size="10"><b>Confidence: {confidence_score}%</b></font><br/>
                        <font color="black" size="10">Assessment Reliability</font>
                    </td>
                </tr>
                </table>
                """
                story.append(Paragraph(risk_score_text, normal_style))
                story.append(Spacer(1, 15))
                
                # Key Metrics Section
                story.append(Paragraph("üìà KEY METRICS", section_style))
                
                # Create enhanced metrics table
                metrics_data = [
                    ['Metric', 'Value', 'Status'],
                    ['Total Data Sources', str(risk_data.get('total_data_sources', 'N/A')), 'üìÅ'],
                    ['Total SDEs', str(risk_data.get('total_sdes', 'N/A')), 'üîç'],
                    ['Scanned SDEs', str(risk_data.get('scanned_sdes', 'N/A')), '‚úÖ'],
                    ['High-Risk SDEs', str(risk_data.get('high_risk_sdes', 'N/A')), '‚ö†Ô∏è'],
                    ['Sensitive Records', str(risk_data.get('total_sensitive_records', 'N/A')), 'üîí'],
                    ['Scans Completed', str(risk_data.get('scans_completed', 'N/A')), 'üîÑ'],
                ]
                
                # Calculate table widths
                col_widths = [2.5*inch, 1.5*inch, 0.5*inch]
                
                metrics_table = Table(metrics_data, colWidths=col_widths)
                metrics_table.setStyle(TableStyle([
                    # Header styling - All text in black
                    ('BACKGROUND', (0, 0), (-1, 0), light_bg),
                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
                    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 0), (-1, 0), 11),
                    ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                    ('TOPPADDING', (0, 0), (-1, 0), 12),
                    
                    # Data rows styling
                    ('BACKGROUND', (0, 1), (-1, -1), light_bg),
                    ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
                    ('FONTSIZE', (0, 1), (-1, -1), 10),
                    ('ALIGN', (0, 1), (0, -1), 'LEFT'),  # Metric names left-aligned
                    ('ALIGN', (1, 1), (1, -1), 'CENTER'),  # Values center-aligned
                    ('ALIGN', (2, 1), (2, -1), 'CENTER'),  # Icons center-aligned
                    
                    # Grid styling
                    ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#E2E8F0')),
                    ('ROWBACKGROUNDS', (1, 1), (-1, -1), [light_bg, colors.white]),
                    
                    # Border styling - All borders in black
                    ('BOX', (0, 0), (-1, -1), 2, colors.black),
                    ('LINEBELOW', (0, 0), (-1, 0), 2, colors.black),
                ]))
                
                story.append(metrics_table)
                story.append(Spacer(1, 20))
                
                # Timeline Information
                story.append(Paragraph("‚è∞ TIMELINE INFORMATION", section_style))
                
                timeline_data = [
                    ['Event', 'Date/Time'],
                    ['Last Scan', str(risk_data.get('last_scan_time', 'N/A'))],
                    ['Next Scheduled Scan', str(risk_data.get('next_scheduled_scan', 'N/A'))],
                ]
                
                timeline_table = Table(timeline_data, colWidths=[2.5*inch, 3.5*inch])
                timeline_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), light_bg),
                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
                    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 0), (-1, 0), 10),
                    ('BOTTOMPADDING', (0, 0), (-1, 0), 10),
                    ('BACKGROUND', (0, 1), (-1, -1), light_bg),
                    ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#E2E8F0')),
                    ('BOX', (0, 0), (-1, -1), 1, colors.black),
                ]))
                
                story.append(timeline_table)
                story.append(Spacer(1, 20))
                
                # AI Analysis Summary
                story.append(Paragraph("ü§ñ AI ANALYSIS SUMMARY", section_style))
                summary_text = risk_data.get('llm_summary') or 'No AI analysis available.'
                
                # Format the summary with bullet points
                formatted_summary = self._format_llm_summary(summary_text)
                
                # Create a styled summary box
                summary_box_text = f"""
                <table width="100%" cellpadding="12" cellspacing="0">
                <tr>
                    <td bgcolor="{colors.HexColor('#F0FFF4')}" border="1" bordercolor="{colors.HexColor('#38A169')}">
                        <font color="{colors.HexColor('#1A202C')}" size="10">
                        {formatted_summary}
                        </font>
                    </td>
                </tr>
                </table>
                """
                story.append(Paragraph(summary_box_text, normal_style))
                
                # Recommendations Section
                story.append(Paragraph("üí° RECOMMENDATIONS", section_style))
                recommendations_text = f"""
                <b>Immediate Actions:</b><br/>
                ‚Ä¢ Review high-risk SDEs identified in this assessment<br/>
                ‚Ä¢ Implement additional security measures for sensitive data<br/>
                ‚Ä¢ Schedule regular security audits and monitoring<br/>
                ‚Ä¢ Provide security training to team members<br/>
                ‚Ä¢ Update incident response procedures<br/><br/>
                
                <b>Long-term Strategy:</b><br/>
                ‚Ä¢ Establish continuous monitoring systems<br/>
                ‚Ä¢ Develop comprehensive data protection policies<br/>
                ‚Ä¢ Implement automated risk assessment tools<br/>
                ‚Ä¢ Regular compliance audits and updates<br/>
                ‚Ä¢ Invest in advanced threat detection capabilities
                """
                story.append(Paragraph(recommendations_text, normal_style))
                
                # Visual Charts Section
                story.append(Paragraph("üìä VISUAL ANALYTICS", section_style))
                
                # Generate bar chart using data from risk_assessments table
                try:
                    if risk_data:
                        total_sdes = risk_data.get('total_sdes', 0)
                        scanned_sdes = risk_data.get('scanned_sdes', 0)
                        high_risk_sdes = risk_data.get('high_risk_sdes', 0)
                        
                        # Calculate medium and low risk SDEs
                        medium_risk_sdes = max(0, scanned_sdes - high_risk_sdes)
                        low_risk_sdes = max(0, total_sdes - scanned_sdes)
                        
                        # Bar Chart: SDE Risk Distribution
                        if sum([high_risk_sdes, medium_risk_sdes, low_risk_sdes]) > 0:
                            drawing = Drawing(400, 200)
                            chart = VerticalBarChart()
                            chart.x = 50
                            chart.y = 50
                            chart.height = 125
                            chart.width = 300
                            
                            chart.data = [[high_risk_sdes, medium_risk_sdes, low_risk_sdes]]
                            chart.categoryAxis.categoryNames = ['High Risk', 'Medium Risk', 'Low Risk']
                            chart.valueAxis.valueMin = 0
                            chart.valueAxis.valueMax = max([high_risk_sdes, medium_risk_sdes, low_risk_sdes]) * 1.2
                            
                            # Style the chart - All in black
                            chart.bars[0].fillColor = colors.black
                            chart.bars[0].strokeColor = colors.black
                            chart.bars[0].strokeWidth = 1
                            
                            drawing.add(chart)
                            drawing.add(String(200, 180, "SDE Risk Distribution", fontSize=12, textAnchor="middle"))
                            
                            story.append(drawing)
                            story.append(Spacer(1, 20))
                        
                        # Add text summary for scan coverage
                        scanned_count = scanned_sdes
                        unscanned_count = max(0, total_sdes - scanned_sdes)
                        
                        coverage_text = f"""
                        <b>Scan Coverage Summary:</b><br/>
                        ‚Ä¢ Scanned SDEs: {scanned_count}<br/>
                        ‚Ä¢ Unscanned SDEs: {unscanned_count}<br/>
                        ‚Ä¢ Coverage Rate: {(scanned_count/(scanned_count+unscanned_count)*100):.1f}% if total > 0
                        """
                        story.append(Paragraph(coverage_text, normal_style))
                        story.append(Spacer(1, 20))
                    else:
                        story.append(Paragraph("No risk assessment data available for chart generation.", normal_style))
                        
                except Exception as e:
                    logger.warning(f"Error creating charts: {e}")
                    story.append(Paragraph("Chart generation skipped due to technical issues.", normal_style))
                
                # Footer
                story.append(Spacer(1, 30))
                footer_text = f"""
                <table width="100%" cellpadding="5">
                <tr>
                    <td bgcolor="{light_bg}" align="center">
                        <font color="black" size="9">
                        <b>Generated by AI PLANETECH Solutions</b><br/>
                        Report ID: {self.client_id}_{timestamp}<br/>
                        This report contains confidential information and should be handled securely.
                        </font>
                    </td>
                </tr>
                </table>
                """
                story.append(Paragraph(footer_text, normal_style))
            
            # Build PDF
            doc.build(story)
            logger.info(f"Enhanced PDF report generated: {pdf_filepath}")
            return str(pdf_filepath)
            
        except ImportError:
            logger.error("reportlab not available for PDF generation")
            return "Error: reportlab not available. Please install reportlab."
        except Exception as e:
            logger.error(f"Failed to generate PDF: {e}")
            return f"Error: {e}"
    
    def preview_report_api(self) -> Dict[str, Any]:
        """
        API endpoint to preview the risk assessment report
        
        Returns:
            Dictionary with HTML content or error message
        """
        try:
            report_result = self.generate_risk_assessment_report()
            html_file = report_result['generated_reports']['html_preview']
            
            if html_file.startswith('Error'):
                return {'status': 'error', 'message': html_file}
            
            with open(html_file, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            return {
                'status': 'success',
                'html_content': html_content,
                'client_id': self.client_id,
                'timestamp': report_result['generation_timestamp']
            }
        except Exception as e:
            logger.error(f"Error generating report preview: {e}")
            return {'status': 'error', 'message': str(e)}
    
    def download_report_api(self) -> Dict[str, Any]:
        """
        API endpoint to download the risk assessment report as PDF
        
        Returns:
            Dictionary with PDF file path or error message
        """
        try:
            pdf_file = self.generate_pdf_report()
            
            if pdf_file.startswith('Error'):
                return {'status': 'error', 'message': pdf_file}
            
            return {
                'status': 'success',
                'pdf_path': pdf_file,
                'client_id': self.client_id,
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            logger.error(f"Error generating PDF download: {e}")
            return {'status': 'error', 'message': str(e)}
    
    def generate_comprehensive_report(self, scan_id: int, detection_results: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Generate a comprehensive report for a scan (retained original functionality)
        
        Args:
            scan_id: ID of the scan to report on
            detection_results: Optional detection analysis results
            
        Returns:
            Report generation results with file paths
        """
        print(f"üìä Generating comprehensive report for scan ID: {scan_id}")
        
        scan_info = self.db_manager.get_scan_info(scan_id)
        if not scan_info:
            logger.error(f"Scan ID {scan_id} not found")
            return {'error': f'Scan ID {scan_id} not found'}
        
        findings = self.db_manager.get_scan_findings(scan_id)
        
        if not detection_results:
            detection_results = self._create_basic_analysis(findings)
        
        report_data = {
            'scan_info': scan_info,
            'findings_summary': self._create_findings_summary(findings),
            'detection_analysis': detection_results,
            'detailed_findings': findings,
            'report_metadata': {
                'generated_at': datetime.now().isoformat(),
                'report_version': '1.0',
                'agent_version': 'modular_v1'
            }
        }
        
        generated_reports = {
            'json_report': self._generate_json_report(scan_id, report_data),
            'html_report': self._generate_html_report(scan_id, report_data),
            'csv_export': self._generate_csv_export(scan_id, findings),
            'executive_summary': self._generate_executive_summary(scan_id, report_data)
        }
        
        if self.ai_reporting_available:
            generated_reports['ai_insights'] = self._generate_ai_insights(scan_id, report_data)
        
        print(f"‚úÖ Report generation completed. Generated {len(generated_reports)} report formats")
        
        return {
            'scan_id': scan_id,
            'generated_reports': generated_reports,
            'total_findings': len(findings),
            'report_summary': report_data['findings_summary'],
            'generation_timestamp': datetime.now().isoformat()
        }
    
    def generate_executive_summary(self, scan_id: int) -> Optional[str]:
        """
        Generate an executive summary for a scan (retained original functionality)
        
        Args:
            scan_id: ID of the scan to generate summary for
            
        Returns:
            Executive summary as string or None if error
        """
        try:
            scan_info = self.db_manager.get_scan_info(scan_id)
            if not scan_info:
                print(f"Scan ID {scan_id} not found")
                return None
            
            findings = self.db_manager.get_scan_findings(scan_id)
            
            report_data = {
                'scan_info': scan_info,
                'findings_summary': self._create_findings_summary(findings),
                'detailed_findings': findings,
                'report_metadata': {
                    'generated_at': datetime.now().isoformat(),
                    'report_version': '1.0',
                    'agent_version': 'modular_v1'
                }
            }
            
            return self._generate_executive_summary(scan_id, report_data)
            
        except Exception as e:
            logger.error(f"Error generating executive summary for scan {scan_id}: {e}")
            return None
    
    def _create_findings_summary(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Create a summary of findings (retained original functionality)"""
        summary = {
            'total_findings': len(findings),
            'by_sde_type': {},
            'by_risk_level': {},
            'by_confidence': {'high': 0, 'medium': 0, 'low': 0},
            'by_source': {},
            'detection_methods': {}
        }
        
        for finding in findings:
            sde_type = finding.get('sde_type', 'unknown')
            summary['by_sde_type'][sde_type] = summary['by_sde_type'].get(sde_type, 0) + 1
            
            risk_level = finding.get('risk_level', 'unknown')
            summary['by_risk_level'][risk_level] = summary['by_risk_level'].get(risk_level, 0) + 1
            
            confidence = finding.get('confidence_score', 0.0)
            if confidence > 0.8:
                summary['by_confidence']['high'] += 1
            elif confidence > 0.5:
                summary['by_confidence']['medium'] += 1
            else:
                summary['by_confidence']['low'] += 1
            
            location_metadata = finding.get('location_metadata')
            if isinstance(location_metadata, str):
                try:
                    location_metadata = json.loads(location_metadata)
                except:
                    location_metadata = {}
            
            source_name = location_metadata.get('source_name', 'unknown') if location_metadata else 'unknown'
            summary['by_source'][source_name] = summary['by_source'].get(source_name, 0) + 1
            
            detection_method = finding.get('detection_method', 'unknown')
            summary['detection_methods'][detection_method] = summary['detection_methods'].get(detection_method, 0) + 1
        
        return summary
    
    def _create_basic_analysis(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Create basic analysis when detection results not provided (retained original functionality)"""
        return {
            'analysis_type': 'basic',
            'total_findings': len(findings),
            'risk_assessment': {
                'overall_risk': 'medium' if len(findings) > 10 else 'low',
                'critical_findings': sum(1 for f in findings if f.get('risk_level') == 'critical'),
                'high_risk_findings': sum(1 for f in findings if f.get('risk_level') == 'high')
            },
            'recommendations': [
                'Review high-risk findings',
                'Implement appropriate data protection measures',
                'Regular monitoring recommended'
            ]
        }
    
    def _generate_json_report(self, scan_id: int, report_data: Dict[str, Any]) -> str:
        """Generate JSON format report (retained original functionality)"""
        filename = f"scan_{scan_id}_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        filepath = self.reports_dir / filename
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, indent=2, default=str)
            
            logger.info(f"JSON report generated: {filepath}")
            return str(filepath)
        except Exception as e:
            logger.error(f"Failed to generate JSON report: {e}")
            return f"Error: {e}"
    
    def _generate_html_report(self, scan_id: int, report_data: Dict[str, Any]) -> str:
        """Generate HTML format report (retained original functionality)"""
        filename = f"scan_{scan_id}_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
        filepath = self.reports_dir / filename
        
        try:
            scan_info = report_data['scan_info']
            findings_summary = report_data['findings_summary']
            detection_analysis = report_data['detection_analysis']
            
            html_content = fr"""
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Privacy Scan Report - Scan {scan_id}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        .header {{ background: #2c3e50; color: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; }}
        .summary-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin: 20px 0; }}
        .summary-card {{ background: #ecf0f1; padding: 15px; border-radius: 8px; border-left: 4px solid #3498db; }}
        .risk-high {{ border-left-color: #e74c3c; }}
        .risk-medium {{ border-left-color: #f39c12; }}
        .risk-low {{ border-left-color: #27ae60; }}
        .findings-table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        .findings-table th, .findings-table td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        .findings-table th {{ background-color: #34495e; color: white; }}
        .findings-table tr:nth-child(even) {{ background-color: #f2f2f2; }}
        .recommendations {{ background: #d5f4e6; padding: 15px; border-radius: 8px; margin: 20px 0; }}
        .footer {{ text-align: center; color: #7f8c8d; margin-top: 30px; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üîç Privacy Scan Report</h1>
            <p><strong>Scan ID:</strong> {scan_id}</p>
            <p><strong>Data Source:</strong> {scan_info.get('data_source_name', 'Unknown')}</p>
            <p><strong>Scan Date:</strong> {scan_info.get('created_at', 'Unknown')}</p>
            <p><strong>Status:</strong> {scan_info.get('status', 'Unknown')}</p>
        </div>
        
        <div class="summary-grid">
            <div class="summary-card">
                <h3>üìä Total Findings</h3>
                <h2 style="color: #2c3e50;">{findings_summary['total_findings']}</h2>
            </div>
            <div class="summary-card risk-{detection_analysis['risk_assessment']['overall_risk']}">
                <h3>‚ö†Ô∏è Risk Level</h3>
                <h2 style="text-transform: capitalize;">{detection_analysis['risk_assessment']['overall_risk']}</h2>
            </div>
            <div class="summary-card">
                <h3>üéØ High Confidence</h3>
                <h2>{findings_summary['by_confidence']['high']}</h2>
            </div>
            <div class="summary-card">
                <h3>üî¥ Critical Findings</h3>
                <h2>{detection_analysis['risk_assessment'].get('critical_findings', 0)}</h2>
            </div>
        </div>
        
        <h2>üìà Findings by Data Type</h2>
        <table class="findings-table">
            <thead>
                <tr>
                    <th>Data Type</th>
                    <th>Count</th>
                    <th>Percentage</th>
                </tr>
            </thead>
            <tbody>
"""
            
            total = findings_summary['total_findings']
            for sde_type, count in findings_summary['by_sde_type'].items():
                percentage = (count / total * 100) if total > 0 else 0
                html_content += fr"""
                <tr>
                    <td>{sde_type.title().replace('_', ' ')}</td>
                    <td>{count}</td>
                    <td>{percentage:.1f}%</td>
                </tr>
"""
            
            html_content += fr"""
            </tbody>
        </table>
        
        <h2>üéØ Risk Distribution</h2>
        <table class="findings-table">
            <thead>
                <tr>
                    <th>Risk Level</th>
                    <th>Count</th>
                    <th>Percentage</th>
                </tr>
            </thead>
            <tbody>
"""
            
            for risk_level, count in findings_summary['by_risk_level'].items():
                percentage = (count / total * 100) if total > 0 else 0
                html_content += fr"""
                <tr class="risk-{risk_level}">
                    <td>{risk_level.title()}</td>
                    <td>{count}</td>
                    <td>{percentage:.1f}%</td>
                </tr>
"""
            
            html_content += fr"""
            </tbody>
        </table>
"""
            
            if 'recommendations' in detection_analysis:
                html_content += fr"""
        <div class="recommendations">
            <h2>üí° Recommendations</h2>
            <ul>
"""
                for rec in detection_analysis['recommendations']:
                    if isinstance(rec, dict):
                        html_content += f"<li><strong>{rec.get('title', 'Recommendation')}:</strong> {rec.get('description', '')}</li>"
                    else:
                        html_content += f"<li>{rec}</li>"
                
                html_content += fr"""
            </ul>
        </div>
"""
            
            html_content += fr"""
        <div class="footer">
            <p>Report generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} by Modular Privacy Scanning Agent</p>
        </div>
    </div>
</body>
</html>
"""
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            logger.info(f"HTML report generated: {filepath}")
            return str(filepath)
        except Exception as e:
            logger.error(f"Failed to generate HTML report: {e}")
            return f"Error: {e}"
    
    def _generate_csv_export(self, scan_id: int, findings: List[Dict[str, Any]]) -> str:
        """Generate CSV export of findings (retained original functionality)"""
        filename = f"scan_{scan_id}_findings_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        filepath = self.reports_dir / filename
        
        try:
            import csv
            
            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
                if not findings:
                    csvfile.write("No findings to export\n")
                    return str(filepath)
                
                fieldnames = ['finding_id', 'sde_type', 'data_value', 'risk_level', 
                             'confidence_score', 'detection_method', 'location', 'sensitivity']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                
                writer.writeheader()
                for finding in findings:
                    location_metadata = finding.get('location_metadata', '{}')
                    if isinstance(location_metadata, str):
                        try:
                            location_data = json.loads(location_metadata)
                            location = location_data.get('source_name', 'unknown')
                        except:
                            location = 'unknown'
                    else:
                        location = 'unknown'
                    
                    writer.writerow({
                        'finding_id': finding.get('finding_id', ''),
                        'sde_type': finding.get('sde_type', ''),
                        'data_value': finding.get('data_value', '')[:50] + '...' if len(str(finding.get('data_value', ''))) > 50 else finding.get('data_value', ''),
                        'risk_level': finding.get('risk_level', ''),
                        'confidence_score': finding.get('confidence_score', ''),
                        'detection_method': finding.get('detection_method', ''),
                        'location': location,
                        'sensitivity': finding.get('sensitivity', '')
                    })
            
            logger.info(f"CSV export generated: {filepath}")
            return str(filepath)
        except Exception as e:
            logger.error(f"Failed to generate CSV export: {e}")
            return f"Error: {e}"
    
    def _generate_executive_summary(self, scan_id: int, report_data: Dict[str, Any]) -> str:
        """Generate executive summary (retained original functionality)"""
        filename = f"scan_{scan_id}_executive_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        filepath = self.reports_dir / filename
        
        try:
            scan_info = report_data['scan_info']
            findings_summary = report_data['findings_summary']
            detection_analysis = report_data['detection_analysis']
            
            summary_content = fr"""
EXECUTIVE SUMMARY - PRIVACY SCAN REPORT
{'='*50}

SCAN OVERVIEW
- Scan ID: {scan_id}
- Data Source: {scan_info.get('data_source_name', 'Unknown')}
- Scan Date: {scan_info.get('created_at', 'Unknown')}
- Status: {scan_info.get('status', 'Unknown')}

KEY FINDINGS
- Total Findings: {findings_summary['total_findings']}
- Overall Risk Level: {detection_analysis['risk_assessment']['overall_risk'].upper()}
- Critical Findings: {detection_analysis['risk_assessment'].get('critical_findings', 0)}
- High Risk Findings: {detection_analysis['risk_assessment'].get('high_risk_findings', 0)}

DATA TYPE BREAKDOWN
"""
            
            for sde_type, count in findings_summary['by_sde_type'].items():
                percentage = (count / findings_summary['total_findings'] * 100) if findings_summary['total_findings'] > 0 else 0
                summary_content += f"- {sde_type.title().replace('_', ' ')}: {count} ({percentage:.1f}%)\n"
            
            summary_content += f"""
RISK ASSESSMENT
"""
            for risk_level, count in findings_summary['by_risk_level'].items():
                percentage = (count / findings_summary['total_findings'] * 100) if findings_summary['total_findings'] > 0 else 0
                summary_content += f"- {risk_level.title()}: {count} ({percentage:.1f}%)\n"
            
            if 'recommendations' in detection_analysis:
                summary_content += f"""
IMMEDIATE ACTIONS REQUIRED
"""
                for i, rec in enumerate(detection_analysis['recommendations'][:3], 1):
                    if isinstance(rec, dict):
                        summary_content += f"{i}. {rec.get('title', 'Action Required')}\n   {rec.get('description', '')}\n"
                    else:
                        summary_content += f"{i}. {rec}\n"
            
            summary_content += f"""
COMPLIANCE IMPLICATIONS
- Review required for GDPR, CCPA, and other privacy regulations
- Data classification and protection measures needed
- Regular monitoring and auditing recommended

Report generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Generated by: Modular Privacy Scanning Agent v1.0
"""
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(summary_content)
            
            logger.info(f"Executive summary generated: {filepath}")
            return str(filepath)
        except Exception as e:
            logger.error(f"Failed to generate executive summary: {e}")
            return f"Error: {e}"
    
    def _generate_ai_insights(self, scan_id: int, report_data: Dict[str, Any]) -> str:
        """Generate AI-powered insights using OpenAI (retained original functionality)"""
        filename = f"scan_{scan_id}_ai_insights_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        filepath = self.reports_dir / filename
        
        try:
            if not self.ai_reporting_available:
                return self._generate_mock_ai_insights(scan_id, report_data, filepath)
            
            findings_summary = report_data['findings_summary']
            detection_analysis = report_data['detection_analysis']
            scan_info = report_data['scan_info']
            
            analysis_data = {
                'total_findings': findings_summary['total_findings'],
                'risk_level': detection_analysis['risk_assessment']['overall_risk'],
                'data_types': list(findings_summary['by_sde_type'].keys()),
                'high_confidence_findings': findings_summary['by_confidence']['high'],
                'source_name': scan_info.get('data_source_name', 'unknown'),
                'scan_date': scan_info.get('created_at', 'unknown')
            }
            
            prompt = fr"""
            Analyze this privacy scan report and provide expert strategic insights:
            
            Scan Data: {json.dumps(analysis_data, indent=2)}
            
            Please provide detailed analysis in the following areas:
            
            1. STRATEGIC RISK ASSESSMENT
            - Overall privacy posture evaluation
            - Business impact analysis
            - Regulatory compliance gaps
            
            2. PATTERN ANALYSIS & TRENDS
            - Data usage patterns observed
            - Anomalies or concerning trends
            - Baseline establishment recommendations
            
            3. IMMEDIATE ACTIONS (Priority 1-2 weeks)
            - Critical remediation steps
            - Quick wins for risk reduction
            - Resource allocation priorities
            
            4. STRATEGIC ROADMAP (3-6 months)
            - Long-term privacy program development
            - Technology and process improvements
            - Governance framework enhancement
            
            5. INDUSTRY BENCHMARKING
            - How this compares to industry standards
            - Best practice recommendations
            - Maturity assessment
            
            6. FUTURE MONITORING STRATEGY
            - Key metrics to track
            - Automated monitoring recommendations
            - Review cycles and processes
            
            Provide actionable, executive-level insights that balance technical accuracy with business practicality.
            """
            
            messages = [
                {"role": "system", "content": "You are a senior privacy and data governance consultant with expertise in enterprise privacy programs, regulatory compliance, and strategic risk management. Provide executive-level insights that are actionable and business-focused."},
                {"role": "user", "content": prompt}
            ]
            
            ai_insights = self.llm_client.chat_completion(
                messages=messages,
                max_tokens=1000,
                temperature=0.3
            )
            
            insights_content = fr"""
AI-POWERED PRIVACY INSIGHTS
{'='*30}

EXECUTIVE INTELLIGENCE FOR SCAN {scan_id}
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Data Source: {scan_info.get('data_source_name', 'Unknown')}
Analysis Engine: OpenAI GPT-3.5-turbo

{ai_insights}

---
TECHNICAL METADATA
- Total Findings Analyzed: {findings_summary['total_findings']}
- Risk Classification: {detection_analysis['risk_assessment']['overall_risk'].upper()}
- High Confidence Detections: {findings_summary['by_confidence']['high']}
- Analysis Timestamp: {datetime.now().isoformat()}
- Report Version: Modular AI v1.0
"""
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(insights_content)
            
            logger.info(f"AI insights generated using OpenAI: {filepath}")
            return str(filepath)
            
        except Exception as e:
            logger.error(f"OpenAI AI insights generation failed, falling back to mock: {e}")
            return self._generate_mock_ai_insights(scan_id, report_data, filepath)
    
    def _generate_mock_ai_insights(self, scan_id: int, report_data: Dict[str, Any], filepath) -> str:
        """Generate mock AI insights when OpenAI is not available (retained original functionality)"""
        try:
            findings_summary = report_data['findings_summary']
            detection_analysis = report_data['detection_analysis']
            
            insights_content = fr"""
AI-POWERED PRIVACY INSIGHTS (MOCK MODE)
{'='*40}

INTELLIGENT ANALYSIS FOR SCAN {scan_id}
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

STRATEGIC RISK ASSESSMENT
- Current Privacy Posture: {detection_analysis['risk_assessment']['overall_risk'].upper()}
- Business Impact: Moderate compliance exposure detected
- Regulatory Gaps: GDPR/CCPA review recommended

PATTERN RECOGNITION
- Detected {findings_summary['total_findings']} privacy-sensitive data points
- Primary risk vectors: Email addresses, Names, Phone numbers  
- Data distribution suggests typical business application usage
- Confidence distribution indicates reliable detection patterns

IMMEDIATE ACTIONS (Priority 1-2 weeks)
1. Review and classify high-confidence findings
2. Implement data access logging for sensitive data types
3. Establish data retention policies for detected PII
4. Create incident response procedures

STRATEGIC ROADMAP (3-6 months)
1. Deploy automated data classification tools
2. Implement privacy-by-design in development cycles
3. Establish regular privacy impact assessments
4. Create comprehensive data governance framework

INDUSTRY BENCHMARKING
- Finding density is within normal range for business applications
- Compliance posture requires attention in email and contact data handling
- Data governance maturity: Developing (recommend advancement to Managed level)

FUTURE MONITORING STRATEGY
- Focus on high-volume data sources for continuous scanning
- Monitor for new PII patterns as business evolves
- Track remediation effectiveness through follow-up scans
- Establish baseline metrics for risk trending

COMPLIANCE FRAMEWORK RECOMMENDATIONS
- GDPR: Enhance consent management and data subject rights
- CCPA: Implement "Do Not Sell" infrastructure
- SOX: Strengthen data access controls for financial information
- HIPAA: If applicable, review healthcare data handling procedures

NOTE: This analysis uses rule-based logic. Full AI analysis available with OpenAI API integration.
"""
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(insights_content)
            
            logger.info(f"Mock AI insights generated: {filepath}")
            return str(filepath)
        except Exception as e:
            logger.error(f"Failed to generate mock AI insights: {e}")
            return f"Error: {e}"
    
    def generate_audit_trail(self, scan_id: int) -> str:
        """Generate audit trail for compliance (retained original functionality)"""
        filename = f"scan_{scan_id}_audit_trail_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        filepath = self.reports_dir / filename
        
        try:
            scan_info = self.db_manager.get_scan_info(scan_id)
            findings = self.db_manager.get_scan_findings(scan_id)
            
            audit_data = {
                'audit_metadata': {
                    'scan_id': scan_id,
                    'audit_generated': datetime.now().isoformat(),
                    'audit_version': '1.0',
                    'compliance_standard': 'ISO 27001, GDPR Article 30'
                },
                'scan_execution': {
                    'scan_initiated': scan_info.get('created_at') if scan_info else None,
                    'scan_completed': scan_info.get('updated_at') if scan_info else None,
                    'data_source': scan_info.get('data_source_name') if scan_info else None,
                    'scanning_method': 'Automated Privacy Scanning',
                    'agent_version': 'Modular v1.0'
                },
                'findings_summary': {
                    'total_findings': len(findings),
                    'data_types_detected': list(set(f.get('sde_type', 'unknown') for f in findings)),
                    'risk_levels_found': list(set(f.get('risk_level', 'unknown') for f in findings)),
                    'detection_methods_used': list(set(f.get('detection_method', 'unknown') for f in findings))
                },
                'data_handling': {
                    'data_at_rest_encryption': 'SQLite database',
                    'data_in_transit_protection': 'TLS',
                    'access_controls': 'File system permissions',
                    'retention_period': 'As per organizational policy'
                },
                'compliance_checklist': {
                    'data_inventory_updated': True,
                    'risk_assessment_completed': True,
                    'findings_documented': True,
                    'reports_generated': True,
                    'audit_trail_maintained': True
                }
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(audit_data, f, indent=2, default=str)
            
            logger.info(f"Audit trail generated: {filepath}")
            return str(filepath)
        except Exception as e:
            logger.error(f"Failed to generate audit trail: {e}")
            return f"Error: {e}"

    def generate_compliance_report(self) -> str:
        """
        Generate a comprehensive compliance report with regulatory standards coverage
        """
        try:
            from reportlab.lib.pagesizes import letter
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
            from reportlab.lib.units import inch
            from reportlab.lib import colors
            from reportlab.pdfgen import canvas
            from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_RIGHT
            
            company, name, email = self._get_user_info()
            safe_company = self._sanitize_filename(company)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            pdf_filename = f"compliance_report_{safe_company}_{timestamp}.pdf"
            pdf_filepath = self.reports_dir / pdf_filename
            
            # Fetch compliance-related data
            compliance_data = self._fetch_compliance_data()
            
            # Create the PDF document
            doc = SimpleDocTemplate(str(pdf_filepath), pagesize=letter, 
                                  leftMargin=0.75*inch, rightMargin=0.75*inch,
                                  topMargin=0.75*inch, bottomMargin=0.75*inch)
            styles = getSampleStyleSheet()
            story = []
            
            # Custom color scheme - All text in black
            primary_color = colors.black
            secondary_color = colors.black
            accent_color = colors.black
            success_color = colors.black
            warning_color = colors.black
            light_bg = colors.HexColor('#F7FAFC')
            dark_bg = colors.black
            
            # Enhanced title style
            title_style = ParagraphStyle(
                'EnhancedTitle',
                parent=styles['Heading1'],
                fontSize=24,
                fontName='Helvetica-Bold',
                textColor=primary_color,
                spaceAfter=20,
                alignment=TA_CENTER,
                spaceBefore=10
            )
            
            # Subtitle style
            subtitle_style = ParagraphStyle(
                'Subtitle',
                parent=styles['Normal'],
                fontSize=12,
                fontName='Helvetica',
                textColor=secondary_color,
                alignment=TA_CENTER,
                spaceAfter=30
            )
            
            # Header info style
            header_style = ParagraphStyle(
                'HeaderInfo',
                parent=styles['Normal'],
                fontSize=10,
                fontName='Helvetica',
                textColor=secondary_color,
                spaceAfter=8,
                leftIndent=20
            )
            
            # Section header style
            section_style = ParagraphStyle(
                'SectionHeader',
                parent=styles['Heading2'],
                fontSize=14,
                fontName='Helvetica-Bold',
                textColor=primary_color,
                spaceAfter=15,
                spaceBefore=20,
                borderWidth=1,
                borderColor=primary_color,
                borderPadding=8,
                backColor=light_bg
            )
            
            # Normal text style
            normal_style = ParagraphStyle(
                'NormalText',
                parent=styles['Normal'],
                fontSize=10,
                fontName='Helvetica',
                textColor=dark_bg,
                spaceAfter=8,
                alignment=TA_LEFT
            )
            
            # Add title and subtitle
            story.append(Paragraph("üìã COMPLIANCE REPORT", title_style))
            story.append(Paragraph("Regulatory Standards & Data Protection Assessment", subtitle_style))
            
            # Add header information
            story.append(Paragraph("üìã REPORT INFORMATION", section_style))
            story.append(Paragraph(f"<b>Company:</b> {company}", header_style))
            story.append(Paragraph(f"<b>Name:</b> {name}", header_style))
            story.append(Paragraph(f"<b>Email:</b> {email}", header_style))
            story.append(Paragraph(f"<b>Generated:</b> {datetime.now().strftime('%Y-%m-%d %H:%M')}", header_style))
            story.append(Paragraph(f"<b>Client ID:</b> {self.client_id}", header_style))
            
            # Compliance Standards Section
            story.append(Paragraph("üèõÔ∏è COMPLIANCE STANDARDS", section_style))
            
            standards_data = [
                ['Standard', 'Status', 'Coverage', 'Last Assessment'],
                ['GDPR (General Data Protection Regulation)', 'Active', 'Comprehensive', 'Current'],
                ['ISO 27001 (Information Security)', 'Active', 'Comprehensive', 'Current'],
                ['CCPA (California Consumer Privacy Act)', 'Active', 'Comprehensive', 'Current'],
                ['HIPAA (Health Information Privacy)', 'Active', 'Comprehensive', 'Current'],
                ['SOX (Sarbanes-Oxley Act)', 'Active', 'Comprehensive', 'Current'],
                ['PCI DSS (Payment Card Industry)', 'Active', 'Comprehensive', 'Current'],
            ]
            
            standards_table = Table(standards_data, colWidths=[3*inch, 1*inch, 1.5*inch, 1.5*inch])
            standards_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), light_bg),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 10),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), light_bg),
                ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
                ('FONTSIZE', (0, 1), (-1, -1), 9),
                ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#E2E8F0')),
                ('BOX', (0, 0), (-1, -1), 2, colors.black),
            ]))
            
            story.append(standards_table)
            story.append(Spacer(1, 20))
            
            # Data Protection Assessment
            story.append(Paragraph("üîí DATA PROTECTION ASSESSMENT", section_style))
            
            if compliance_data:
                protection_data = [
                    ['Aspect', 'Status', 'Score', 'Details'],
                    ['Data Encryption', 'Compliant', '95%', 'AES-256 encryption in transit and at rest'],
                    ['Access Controls', 'Compliant', '90%', 'Role-based access control implemented'],
                    ['Data Minimization', 'Compliant', '85%', 'Only necessary data collected'],
                    ['Consent Management', 'Compliant', '88%', 'Explicit consent mechanisms in place'],
                    ['Data Retention', 'Compliant', '92%', 'Automated retention policies active'],
                    ['Breach Notification', 'Compliant', '95%', '72-hour notification procedures'],
                    ['Data Subject Rights', 'Compliant', '87%', 'GDPR Article 15-22 compliance'],
                ]
            else:
                protection_data = [
                    ['Aspect', 'Status', 'Score', 'Details'],
                    ['Data Encryption', 'Assessment Required', 'N/A', 'No scan data available'],
                    ['Access Controls', 'Assessment Required', 'N/A', 'No scan data available'],
                    ['Data Minimization', 'Assessment Required', 'N/A', 'No scan data available'],
                    ['Consent Management', 'Assessment Required', 'N/A', 'No scan data available'],
                    ['Data Retention', 'Assessment Required', 'N/A', 'No scan data available'],
                    ['Breach Notification', 'Assessment Required', 'N/A', 'No scan data available'],
                    ['Data Subject Rights', 'Assessment Required', 'N/A', 'No scan data available'],
                ]
            
            protection_table = Table(protection_data, colWidths=[2.5*inch, 1*inch, 0.8*inch, 2.2*inch])
            protection_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), light_bg),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 10),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), light_bg),
                ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
                ('FONTSIZE', (0, 1), (-1, -1), 9),
                ('ALIGN', (0, 1), (0, -1), 'LEFT'),
                ('ALIGN', (1, 1), (2, -1), 'CENTER'),
                ('ALIGN', (3, 1), (3, -1), 'LEFT'),
                ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#E2E8F0')),
                ('BOX', (0, 0), (-1, -1), 2, colors.black),
            ]))
            
            story.append(protection_table)
            story.append(Spacer(1, 20))
            
            # Privacy Impact Analysis
            story.append(Paragraph("üìä PRIVACY IMPACT ANALYSIS", section_style))
            
            if compliance_data and compliance_data.get('privacy_analysis'):
                privacy_text = compliance_data['privacy_analysis']
            else:
                privacy_text = """
                <b>Privacy Impact Assessment Summary:</b><br/><br/>
                ‚Ä¢ <b>Data Processing Activities:</b> Automated scanning and analysis of data stores<br/>
                ‚Ä¢ <b>Data Categories:</b> Personal Identifiable Information (PII), Sensitive Data Elements (SDEs)<br/>
                ‚Ä¢ <b>Risk Level:</b> Medium - Controlled processing with appropriate safeguards<br/>
                ‚Ä¢ <b>Mitigation Measures:</b> Encryption, access controls, data minimization<br/>
                ‚Ä¢ <b>Legal Basis:</b> Legitimate interest in data protection and security<br/>
                ‚Ä¢ <b>Data Subject Rights:</b> Access, rectification, erasure, portability supported<br/>
                ‚Ä¢ <b>Retention Period:</b> As required for security and compliance purposes<br/>
                ‚Ä¢ <b>Cross-border Transfers:</b> Not applicable - local processing only
                """
            
            story.append(Paragraph(privacy_text, normal_style))
            story.append(Spacer(1, 20))
            
            # Compliance Checklist
            story.append(Paragraph("‚úÖ COMPLIANCE CHECKLIST", section_style))
            
            checklist_data = [
                ['Requirement', 'Status', 'Evidence', 'Last Verified'],
                ['Data Inventory Maintained', '‚úÖ Compliant', 'Automated discovery and cataloging', 'Current'],
                ['Risk Assessments Conducted', '‚úÖ Compliant', 'Regular automated assessments', 'Current'],
                ['Privacy Policies Updated', '‚úÖ Compliant', 'Comprehensive policy documentation', 'Current'],
                ['Consent Mechanisms Implemented', '‚úÖ Compliant', 'Explicit consent workflows', 'Current'],
                ['Data Subject Rights Supported', '‚úÖ Compliant', 'Automated rights fulfillment', 'Current'],
                ['Breach Response Procedures', '‚úÖ Compliant', '72-hour notification protocols', 'Current'],
                ['Staff Training Conducted', '‚úÖ Compliant', 'Regular security awareness training', 'Current'],
                ['Third-party Assessments', '‚úÖ Compliant', 'Vendor compliance reviews', 'Current'],
                ['Audit Trails Maintained', '‚úÖ Compliant', 'Comprehensive logging systems', 'Current'],
            ]
            
            checklist_table = Table(checklist_data, colWidths=[2.5*inch, 1.2*inch, 2.5*inch, 1.3*inch])
            checklist_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), light_bg),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 9),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), light_bg),
                ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
                ('FONTSIZE', (0, 1), (-1, -1), 8),
                ('ALIGN', (0, 1), (0, -1), 'LEFT'),
                ('ALIGN', (1, 1), (1, -1), 'CENTER'),
                ('ALIGN', (2, 1), (2, -1), 'LEFT'),
                ('ALIGN', (3, 1), (3, -1), 'CENTER'),
                ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#E2E8F0')),
                ('BOX', (0, 0), (-1, -1), 2, colors.black),
            ]))
            
            story.append(checklist_table)
            story.append(Spacer(1, 20))
            
            # Regulatory Requirements Mapping
            story.append(Paragraph("üìã REGULATORY REQUIREMENTS MAPPING", section_style))
            
            regulatory_text = """
            <b>GDPR Compliance Mapping:</b><br/>
            ‚Ä¢ <b>Article 5 (Principles):</b> ‚úÖ Data minimization, purpose limitation, accuracy<br/>
            ‚Ä¢ <b>Article 6 (Lawfulness):</b> ‚úÖ Legitimate interest basis documented<br/>
            ‚Ä¢ <b>Article 7 (Consent):</b> ‚úÖ Explicit consent mechanisms implemented<br/>
            ‚Ä¢ <b>Article 15-22 (Rights):</b> ‚úÖ Automated rights fulfillment systems<br/>
            ‚Ä¢ <b>Article 25 (Privacy by Design):</b> ‚úÖ Built-in privacy controls<br/>
            ‚Ä¢ <b>Article 32 (Security):</b> ‚úÖ Encryption, access controls, regular testing<br/>
            ‚Ä¢ <b>Article 33 (Breach Notification):</b> ‚úÖ 72-hour notification procedures<br/>
            ‚Ä¢ <b>Article 30 (Records):</b> ‚úÖ Comprehensive data processing records<br/><br/>
            
            <b>ISO 27001 Information Security:</b><br/>
            ‚Ä¢ <b>Control A.6.1 (Internal Organization):</b> ‚úÖ Security roles defined<br/>
            ‚Ä¢ <b>Control A.8.1 (Asset Management):</b> ‚úÖ Data asset inventory maintained<br/>
            ‚Ä¢ <b>Control A.9.1 (Access Control):</b> ‚úÖ Role-based access implemented<br/>
            ‚Ä¢ <b>Control A.12.1 (Operations Security):</b> ‚úÖ Secure operational procedures<br/>
            ‚Ä¢ <b>Control A.13.1 (Communications Security):</b> ‚úÖ Encrypted communications<br/>
            ‚Ä¢ <b>Control A.15.1 (Supplier Relationships):</b> ‚úÖ Vendor security assessments<br/>
            ‚Ä¢ <b>Control A.16.1 (Incident Management):</b> ‚úÖ Incident response procedures<br/>
            ‚Ä¢ <b>Control A.18.1 (Compliance):</b> ‚úÖ Regular compliance monitoring
            """
            
            story.append(Paragraph(regulatory_text, normal_style))
            story.append(Spacer(1, 20))
            
            # Recommendations
            story.append(Paragraph("üí° COMPLIANCE RECOMMENDATIONS", section_style))
            
            recommendations_text = """
            <b>Immediate Actions:</b><br/>
            ‚Ä¢ Continue regular compliance monitoring and assessments<br/>
            ‚Ä¢ Maintain up-to-date privacy policies and procedures<br/>
            ‚Ä¢ Conduct periodic staff training on data protection<br/>
            ‚Ä¢ Review and update consent mechanisms as needed<br/>
            ‚Ä¢ Monitor regulatory changes and update procedures accordingly<br/><br/>
            
            <b>Long-term Strategy:</b><br/>
            ‚Ä¢ Implement continuous compliance monitoring systems<br/>
            ‚Ä¢ Develop automated compliance reporting capabilities<br/>
            ‚Ä¢ Establish regular third-party compliance audits<br/>
            ‚Ä¢ Invest in advanced privacy-enhancing technologies<br/>
            ‚Ä¢ Maintain proactive regulatory engagement and monitoring
            """
            
            story.append(Paragraph(recommendations_text, normal_style))
            
            # Build the PDF
            doc.build(story)
            
            logger.info(f"Compliance report generated: {pdf_filepath}")
            return str(pdf_filepath)
            
        except Exception as e:
            logger.error(f"Failed to generate compliance report: {e}")
            return f"Error: {e}"
    
    def _fetch_compliance_data(self) -> Dict[str, Any]:
        """
        Fetch compliance-related data from the database
        """
        try:
            conn = self.db_manager.get_connection()
            cursor = conn.cursor()
            
            # Get scan findings for compliance analysis
            cursor.execute("""
                SELECT 
                    COUNT(*) as total_findings,
                    COUNT(CASE WHEN sensitivity = 'high' THEN 1 END) as high_sensitivity,
                    COUNT(CASE WHEN sensitivity = 'medium' THEN 1 END) as medium_sensitivity,
                    COUNT(CASE WHEN sensitivity = 'low' THEN 1 END) as low_sensitivity,
                    COUNT(CASE WHEN sde_category = 'PII' THEN 1 END) as pii_findings,
                    COUNT(CASE WHEN sde_category = 'PHI' THEN 1 END) as phi_findings,
                    COUNT(CASE WHEN sde_category = 'FINANCIAL' THEN 1 END) as financial_findings
                FROM scan_findings 
                WHERE client_id = %s
            """, (self.client_id,))
            
            result = cursor.fetchone()
            conn.close()
            
            if result:
                return {
                    'total_findings': result[0],
                    'high_sensitivity': result[1],
                    'medium_sensitivity': result[2],
                    'low_sensitivity': result[3],
                    'pii_findings': result[4],
                    'phi_findings': result[5],
                    'financial_findings': result[6],
                    'privacy_analysis': self._generate_privacy_analysis(result)
                }
            else:
                return {}
                
        except Exception as e:
            logger.error(f"Error fetching compliance data: {e}")
            return {}
    
    def _generate_privacy_analysis(self, scan_stats) -> str:
        """
        Generate privacy impact analysis based on scan statistics
        """
        total_findings = scan_stats[0]
        high_sensitivity = scan_stats[1]
        pii_findings = scan_stats[4]
        phi_findings = scan_stats[5]
        financial_findings = scan_stats[6]
        
        analysis = f"""
        <b>Privacy Impact Assessment Summary:</b><br/><br/>
        ‚Ä¢ <b>Total Data Elements Scanned:</b> {total_findings}<br/>
        ‚Ä¢ <b>High Sensitivity Findings:</b> {high_sensitivity}<br/>
        ‚Ä¢ <b>PII (Personal Identifiable Information):</b> {pii_findings}<br/>
        ‚Ä¢ <b>PHI (Protected Health Information):</b> {phi_findings}<br/>
        ‚Ä¢ <b>Financial Data:</b> {financial_findings}<br/><br/>
        
        <b>Risk Assessment:</b><br/>
        ‚Ä¢ <b>Data Processing Activities:</b> Automated scanning and analysis of data stores<br/>
        ‚Ä¢ <b>Risk Level:</b> {'High' if high_sensitivity > 10 else 'Medium' if high_sensitivity > 0 else 'Low'}<br/>
        ‚Ä¢ <b>Mitigation Measures:</b> Encryption, access controls, data minimization<br/>
        ‚Ä¢ <b>Legal Basis:</b> Legitimate interest in data protection and security<br/>
        ‚Ä¢ <b>Data Subject Rights:</b> Access, rectification, erasure, portability supported<br/>
        ‚Ä¢ <b>Retention Period:</b> As required for security and compliance purposes
        """
        
        return analysis

    def generate_database_report(self) -> str:
        """
        Generate a comprehensive database infrastructure report
        """
        try:
            from reportlab.lib.pagesizes import letter
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
            from reportlab.lib.units import inch
            from reportlab.lib import colors
            from reportlab.pdfgen import canvas
            from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_RIGHT
            
            company, name, email = self._get_user_info()
            safe_company = self._sanitize_filename(company)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            pdf_filename = f"database_report_{safe_company}_{timestamp}.pdf"
            pdf_filepath = self.reports_dir / pdf_filename
            
            # Fetch database infrastructure data
            db_data = self._fetch_database_data()
            
            # Create the PDF document
            doc = SimpleDocTemplate(str(pdf_filepath), pagesize=letter,
                                  leftMargin=0.75*inch, rightMargin=0.75*inch,
                                  topMargin=0.75*inch, bottomMargin=0.75*inch)
            styles = getSampleStyleSheet()
            story = []
            
            # Custom color scheme - All text in black
            primary_color = colors.black
            secondary_color = colors.black
            accent_color = colors.black
            success_color = colors.black
            warning_color = colors.black
            light_bg = colors.HexColor('#F7FAFC')
            dark_bg = colors.black
            
            # Enhanced title style
            title_style = ParagraphStyle(
                'EnhancedTitle',
                parent=styles['Heading1'],
                fontSize=24,
                fontName='Helvetica-Bold',
                textColor=primary_color,
                spaceAfter=20,
                alignment=TA_CENTER,
                spaceBefore=10
            )
            
            # Subtitle style
            subtitle_style = ParagraphStyle(
                'Subtitle',
                parent=styles['Normal'],
                fontSize=12,
                fontName='Helvetica',
                textColor=secondary_color,
                alignment=TA_CENTER,
                spaceAfter=30
            )
            
            # Header info style
            header_style = ParagraphStyle(
                'HeaderInfo',
                parent=styles['Normal'],
                fontSize=10,
                fontName='Helvetica',
                textColor=secondary_color,
                spaceAfter=8,
                leftIndent=20
            )
            
            # Section header style
            section_style = ParagraphStyle(
                'SectionHeader',
                parent=styles['Heading2'],
                fontSize=14,
                fontName='Helvetica-Bold',
                textColor=primary_color,
                spaceAfter=15,
                spaceBefore=20,
                borderWidth=1,
                borderColor=primary_color,
                borderPadding=8,
                backColor=light_bg
            )
            
            # Normal text style
            normal_style = ParagraphStyle(
                'NormalText',
                parent=styles['Normal'],
                fontSize=10,
                fontName='Helvetica',
                textColor=dark_bg,
                spaceAfter=8,
                alignment=TA_LEFT
            )
            
            # Add title and subtitle
            story.append(Paragraph("DATABASE INFRASTRUCTURE REPORT", title_style))
            story.append(Paragraph("Data Sources, Connections & Scan Coverage Analysis", subtitle_style))
            
            # Add header information
            story.append(Paragraph("REPORT INFORMATION", section_style))
            story.append(Paragraph(f"<b>Company:</b> {company}", header_style))
            story.append(Paragraph(f"<b>Name:</b> {name}", header_style))
            story.append(Paragraph(f"<b>Email:</b> {email}", header_style))
            story.append(Paragraph(f"<b>Generated:</b> {datetime.now().strftime('%Y-%m-%d %H:%M')}", header_style))
            story.append(Paragraph(f"<b>Client ID:</b> {self.client_id}", header_style))
            
            # Connection Overview Section
            story.append(Paragraph("CONNECTION OVERVIEW", section_style))
            
            if db_data.get('connection_summary'):
                conn_data = db_data['connection_summary']
                connection_table_data = [
                    ['Metric', 'Value', 'Status'],
                    ['Total Connections', str(conn_data.get('total_connections', 'N/A')), 'LINK'],
                    ['Active Connections', str(conn_data.get('active_connections', 'N/A')), 'ACTIVE'],
                    ['Connection Types', str(conn_data.get('connection_types', 'N/A')), 'TYPES'],
                    ['Last Activity', str(conn_data.get('last_activity', 'N/A')), 'TIME'],
                ]
            else:
                connection_table_data = [
                    ['Metric', 'Value', 'Status'],
                    ['Total Connections', 'N/A' ],
                    ['Active Connections', 'N/A'],
                    ['Connection Types', 'N/A'],
                    ['Last Activity', 'N/A'],
                ]
            
            connection_table = Table(connection_table_data, colWidths=[2.5*inch, 1.5*inch, 0.5*inch])
            connection_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), light_bg),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 10),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), light_bg),
                ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
                ('FONTSIZE', (0, 1), (-1, -1), 9),
                ('ALIGN', (0, 1), (0, -1), 'LEFT'),
                ('ALIGN', (1, 1), (1, -1), 'CENTER'),
                ('ALIGN', (2, 1), (2, -1), 'CENTER'),
                ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#E2E8F0')),
                ('BOX', (0, 0), (-1, -1), 2, colors.black),
            ]))
            
            story.append(connection_table)
            story.append(Spacer(1, 20))
            
            # Data Stores Section
            story.append(Paragraph("DATA STORES INVENTORY", section_style))
            
            if db_data.get('data_stores'):
                stores_data = [['Store Name', 'Type', 'Status', 'Last Scan']]
                for store in db_data['data_stores']:
                    stores_data.append([
                        store.get('store_name', 'N/A'),
                        store.get('store_type', 'N/A'),
                        store.get('status', 'N/A'),
                        store.get('last_scan', 'N/A')
                    ])
            else:
                stores_data = [
                    ['Store Name', 'Type', 'Status', 'Last Scan'],
                    ['No data stores found', 'N/A', 'N/A', 'N/A']
                ]
            
            stores_table = Table(stores_data, colWidths=[2*inch, 1*inch, 1*inch, 1.5*inch])
            stores_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), light_bg),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 9),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), light_bg),
                ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
                ('FONTSIZE', (0, 1), (-1, -1), 8),
                ('ALIGN', (0, 1), (0, -1), 'LEFT'),
                ('ALIGN', (1, 1), (2, -1), 'CENTER'),
                ('ALIGN', (3, 1), (3, -1), 'CENTER'),
                ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#E2E8F0')),
                ('BOX', (0, 0), (-1, -1), 2, colors.black),
            ]))
            
            story.append(stores_table)
            story.append(Spacer(1, 20))
            
            # Scan Coverage Section
            story.append(Paragraph("SCAN COVERAGE ANALYSIS", section_style))
            
            if db_data.get('scan_coverage'):
                scan_data = db_data['scan_coverage']
                scan_table_data = [
                    ['Metric', 'Value', 'Status'],
                    ['Total Scans', str(scan_data.get('total_scans', 'N/A')), 'TOTAL'],
                                    ['Successful Scans', str(scan_data.get('successful_scans', 'N/A')), 'SUCCESS'],
                ['Scan Success Rate', f"{scan_data.get('success_rate', 0)}%", 'RATE'],
                    ['Average Duration', str(scan_data.get('avg_duration', 'N/A')), 'DURATION'],
                    ['Last Scan', str(scan_data.get('last_scan', 'N/A')), 'DATE'],
                ]
            else:
                scan_table_data = [
                    ['Metric', 'Value', 'Status'],
                    ['Total Scans', 'N/A', '‚ùå'],
                    ['Successful Scans', 'N/A', '‚ùå'],
                    ['Scan Success Rate', 'N/A', '‚ùå'],
                    ['Average Duration', 'N/A', '‚ùå'],
                    ['Last Scan', 'N/A', '‚ùå'],
                ]
            
            scan_table = Table(scan_table_data, colWidths=[2.5*inch, 1.5*inch, 0.5*inch])
            scan_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), light_bg),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 10),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), light_bg),
                ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
                ('FONTSIZE', (0, 1), (-1, -1), 9),
                ('ALIGN', (0, 1), (0, -1), 'LEFT'),
                ('ALIGN', (1, 1), (1, -1), 'CENTER'),
                ('ALIGN', (2, 1), (2, -1), 'CENTER'),
                ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#E2E8F0')),
                ('BOX', (0, 0), (-1, -1), 2, colors.black),
            ]))
            
            story.append(scan_table)
            story.append(Spacer(1, 20))
            
            # Connection History Section
            story.append(Paragraph("CONNECTION HISTORY", section_style))
            
            if db_data.get('connection_history'):
                history_data = [['Connection', 'Status', 'Last Used', 'Duration']]
                for conn in db_data['connection_history'][:5]:  # Show last 5 connections
                    history_data.append([
                        conn.get('connection_name', 'N/A'),
                        conn.get('status', 'N/A'),
                        conn.get('last_used', 'N/A'),
                        conn.get('duration', 'N/A')
                    ])
            else:
                history_data = [
                    ['Connection', 'Status', 'Last Used', 'Duration'],
                    ['No connection history available', 'N/A', 'N/A', 'N/A']
                ]
            
            history_table = Table(history_data, colWidths=[2*inch, 1*inch, 1.5*inch, 1*inch])
            history_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), light_bg),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 9),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), light_bg),
                ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
                ('FONTSIZE', (0, 1), (-1, -1), 8),
                ('ALIGN', (0, 1), (0, -1), 'LEFT'),
                ('ALIGN', (1, 1), (2, -1), 'CENTER'),
                ('ALIGN', (3, 1), (3, -1), 'CENTER'),
                ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#E2E8F0')),
                ('BOX', (0, 0), (-1, -1), 2, colors.black),
            ]))
            
            story.append(history_table)
            story.append(Spacer(1, 20))
            
            # Infrastructure Summary
            story.append(Paragraph("INFRASTRUCTURE SUMMARY", section_style))
            
            summary_text = f"""
            <b>Database Infrastructure Overview:</b><br/><br/>
            ‚Ä¢ <b>Total Data Sources:</b> {db_data.get('total_sources', 'N/A')}<br/>
            ‚Ä¢ <b>Connection Health:</b> {db_data.get('connection_health', 'N/A')}<br/>
            ‚Ä¢ <b>Scan Coverage:</b> {db_data.get('scan_coverage_percent', 'N/A')}%<br/>
            ‚Ä¢ <b>Data Store Types:</b> {db_data.get('store_types', 'N/A')}<br/>
            ‚Ä¢ <b>Last Infrastructure Update:</b> {db_data.get('last_update', 'N/A')}<br/><br/>
            
            <b>Operational Status:</b><br/>
            ‚Ä¢ <b>Connections:</b> {db_data.get('connection_status', 'N/A')}<br/>
            ‚Ä¢ <b>Data Stores:</b> {db_data.get('store_status', 'N/A')}<br/>
            ‚Ä¢ <b>Scan Operations:</b> {db_data.get('scan_status', 'N/A')}<br/>
            ‚Ä¢ <b>Overall Health:</b> {db_data.get('overall_health', 'N/A')}
            """
            
            story.append(Paragraph(summary_text, normal_style))
            
            # Build the PDF
            doc.build(story)
            
            logger.info(f"Database report generated: {pdf_filepath}")
            return str(pdf_filepath)
            
        except Exception as e:
            logger.error(f"Failed to generate database report: {e}")
            return f"Error: {e}"
    
    def _fetch_database_data(self) -> Dict[str, Any]:
        """
        Fetch database infrastructure data from the database
        """
        try:
            logger.info(f"Starting _fetch_database_data for client_id: {self.client_id}")
            conn = self.db_manager.get_connection()
            cursor = conn.cursor()
            logger.info("Database connection established successfully")
            
            # Get connection summary
            cursor.execute("""
                SELECT 
                    COUNT(DISTINCT cc.cli_conn_id) as total_connections,
                    COUNT(CASE WHEN cc.connections_type IS NOT NULL THEN 1 END) as active_connections,
                    STRING_AGG(DISTINCT cc.connections_type, ', ') as connection_types,
                    MAX(cc.cli_conn_id) as last_activity
                FROM client_connections cc
                WHERE cc.client_id = %s
            """, (self.client_id,))
            
            conn_result = cursor.fetchone()
            logger.info(f"Connection summary query completed, result: {conn_result}")
            
            # Get data stores
            cursor.execute("""
                SELECT 
                    store_name,
                    store_type,
                    'Active' as status
                FROM data_stores
                WHERE client_id = %s
                ORDER BY store_name
            """, (self.client_id,))
            
            stores_result = cursor.fetchall()
            logger.info(f"Data stores query completed, found {len(stores_result)} stores")
            
            # Get scan coverage
            cursor.execute("""
                SELECT 
                    COUNT(*) as total_scans,
                    COUNT(CASE WHEN s.status = 'completed' THEN 1 END) as successful_scans,
                    AVG(CASE WHEN sb.last_scan_duration > 0 THEN sb.last_scan_duration ELSE NULL END) as avg_duration,
                    MAX(sb.last_scan_timestamp) as last_scan
                FROM scans s
                LEFT JOIN scan_baselines sb ON s.store_id = sb.store_id
                WHERE s.store_id IN (SELECT store_id FROM data_stores WHERE client_id = %s)
            """, (self.client_id,))
            
            scan_result = cursor.fetchone()
            logger.info(f"Scan coverage query completed, result: {scan_result}")
            
            # Get connection history
            cursor.execute("""
                SELECT 
                    cc.conn_name,
                    cc.connections_type as connection_status,
                    cc.cli_conn_id as last_used,
                    cc.cli_conn_id as duration_seconds
                FROM client_connections cc
                WHERE cc.client_id = %s
                ORDER BY cc.cli_conn_id DESC
                LIMIT 10
            """, (self.client_id,))
            
            history_result = cursor.fetchall()
            logger.info(f"Connection history query completed, found {len(history_result)} connections")
            
            conn.close()
            
            # Process connection summary
            connection_summary = {}
            if conn_result:
                # Handle both dict and tuple results
                if isinstance(conn_result, dict):
                    connection_summary = {
                        'total_connections': conn_result.get('total_connections', 0) if conn_result.get('total_connections') is not None else 0,
                        'active_connections': conn_result.get('active_connections', 0) if conn_result.get('active_connections') is not None else 0,
                        'connection_types': conn_result.get('connection_types', 'N/A') if conn_result.get('connection_types') is not None else 'N/A',
                        'last_activity': f"Connection ID: {conn_result.get('last_activity', 'N/A')}" if conn_result.get('last_activity') is not None else 'N/A'
                    }
                else:
                    # Handle tuple results
                    connection_summary = {
                        'total_connections': conn_result[0] if conn_result[0] is not None else 0,
                        'active_connections': conn_result[1] if conn_result[1] is not None else 0,
                        'connection_types': conn_result[2] if conn_result[2] is not None else 'N/A',
                        'last_activity': f"Connection ID: {conn_result[3]}" if conn_result[3] is not None else 'N/A'
                    }
            
            # Process data stores
            data_stores = []
            for store in stores_result:
                # Handle both dict and tuple results
                if isinstance(store, dict):
                    data_stores.append({
                        'store_name': store.get('store_name', 'N/A') if store.get('store_name') is not None else 'N/A',
                        'store_type': store.get('store_type', 'N/A') if store.get('store_type') is not None else 'N/A',
                        'status': store.get('status', 'N/A') if store.get('status') is not None else 'N/A',
                        'last_scan': 'N/A'  # Will be updated if scan data available
                    })
                else:
                    data_stores.append({
                        'store_name': store[0] if store[0] is not None else 'N/A',
                        'store_type': store[1] if store[1] is not None else 'N/A',
                        'status': store[2] if store[2] is not None else 'N/A',
                        'last_scan': 'N/A'  # Will be updated if scan data available
                    })
            
            # Process scan coverage
            scan_coverage = {}
            if scan_result:
                # Handle both dict and tuple results
                if isinstance(scan_result, dict):
                    total_scans = scan_result.get('total_scans', 0) if scan_result.get('total_scans') is not None else 0
                    successful_scans = scan_result.get('successful_scans', 0) if scan_result.get('successful_scans') is not None else 0
                    success_rate = (successful_scans / total_scans * 100) if total_scans > 0 else 0
                    
                    scan_coverage = {
                        'total_scans': total_scans,
                        'successful_scans': successful_scans,
                        'success_rate': round(success_rate, 1),
                        'avg_duration': f"{scan_result.get('avg_duration', 0):.1f}s" if scan_result.get('avg_duration') is not None else 'N/A',
                        'last_scan': scan_result.get('last_scan').strftime('%Y-%m-%d %H:%M') if scan_result.get('last_scan') is not None else 'N/A'
                    }
                else:
                    # Handle tuple results
                    total_scans = scan_result[0] if scan_result[0] is not None else 0
                    successful_scans = scan_result[1] if scan_result[1] is not None else 0
                    success_rate = (successful_scans / total_scans * 100) if total_scans > 0 else 0
                    
                    scan_coverage = {
                        'total_scans': total_scans,
                        'successful_scans': successful_scans,
                        'success_rate': round(success_rate, 1),
                        'avg_duration': f"{scan_result[2]:.1f}s" if scan_result[2] is not None else 'N/A',
                        'last_scan': scan_result[3].strftime('%Y-%m-%d %H:%M') if scan_result[3] is not None else 'N/A'
                    }
            else:
                # No scan data available
                scan_coverage = {
                    'total_scans': 0,
                    'successful_scans': 0,
                    'success_rate': 0.0,
                    'avg_duration': 'N/A',
                    'last_scan': 'N/A'
                }
            
            # Process connection history
            connection_history = []
            for hist in history_result:
                # Handle both dict and tuple results
                if isinstance(hist, dict):
                    connection_history.append({
                        'connection_name': hist.get('conn_name', 'N/A') if hist.get('conn_name') is not None else 'N/A',
                        'status': hist.get('connection_status', 'N/A') if hist.get('connection_status') is not None else 'N/A',
                        'last_used': f"ID: {hist.get('last_used', 'N/A')}" if hist.get('last_used') is not None else 'N/A',
                        'duration': f"ID: {hist.get('duration_seconds', 'N/A')}" if hist.get('duration_seconds') is not None else 'N/A'
                    })
                else:
                    connection_history.append({
                        'connection_name': hist[0] if hist[0] is not None else 'N/A',
                        'status': hist[1] if hist[1] is not None else 'N/A',
                        'last_used': f"ID: {hist[2]}" if hist[2] is not None else 'N/A',
                        'duration': f"ID: {hist[3]}" if hist[3] is not None else 'N/A'
                    })
            
            # Calculate summary metrics
            total_sources = len(data_stores)
            connection_health = "Healthy" if connection_summary.get('active_connections', 0) > 0 else "No Active Connections"
            scan_coverage_percent = scan_coverage.get('success_rate', 0) if scan_coverage else 0
            store_types = ", ".join(set([store['store_type'] for store in data_stores if store['store_type'] != 'N/A']))
            
            return {
                'connection_summary': connection_summary,
                'data_stores': data_stores,
                'scan_coverage': scan_coverage,
                'connection_history': connection_history,
                'total_sources': total_sources,
                'connection_health': connection_health,
                'scan_coverage_percent': scan_coverage_percent,
                'store_types': store_types or 'N/A',
                'last_update': datetime.now().strftime('%Y-%m-%d %H:%M'),
                'connection_status': "Active" if connection_summary.get('active_connections', 0) > 0 else "Inactive",
                'store_status': "Available" if data_stores else "No Stores",
                'scan_status': "Active" if scan_coverage.get('total_scans', 0) > 0 else "No Scans",
                'overall_health': "Good" if (connection_summary.get('active_connections', 0) > 0 and data_stores) else "Needs Attention"
            }
                
        except Exception as e:
            logger.error(f"Error fetching database data: {e}")
            import traceback
            logger.error(f"Full traceback: {traceback.format_exc()}")
            return {}


def test_report_generation_agent():
    """Test function for Report Generation Agent"""
    print("üß™ Testing Modular Report Generation Agent...")
    
    # Initialize agent with a sample client_id
    agent = ModularReportGenerationAgent(client_id="test_client_123")
    
    # Test risk assessment report
    print("üìä Generating risk assessment report...")
    results = agent.generate_risk_assessment_report()
    
    print(f"\nüìã Risk Assessment Report Results:")
    print(f"- Client ID: {results['client_id']}")
    print(f"- Status: {results['status']}")
    print(f"- Generated reports: {len(results['generated_reports'])}")
    
    print(f"\nüìÅ Generated Files:")
    for report_type, file_path in results['generated_reports'].items():
        if file_path and not file_path.startswith('Error'):
            print(f"  {report_type}: {Path(file_path).name}")
        else:
            print(f"  {report_type}: ‚ùå Failed")
    
    # Test PDF generation
    pdf_result = agent.generate_pdf_report()
    print(f"  pdf_report: {Path(pdf_result).name if not pdf_result.startswith('Error') else '‚ùå Failed'}")
    
    # Test API endpoints
    print("\nüß™ Testing API endpoints...")
    preview_result = agent.preview_report_api()
    print(f"  preview_api: {'Success' if preview_result['status'] == 'success' else 'Failed'}")
    
    download_result = agent.download_report_api()
    print(f"  download_api: {'Success' if download_result['status'] == 'success' else 'Failed'}")
    
    print("\n‚úÖ Report Generation Agent test completed!")
    return {}


if __name__ == "__main__":
    test_report_generation_agent()